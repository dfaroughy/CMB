#...General experiment parameters
experiment:
  workdir: /home/df630/CMB/results/runs

#...Data parameters

data:
  dataset: JetClass
  target:
    name: tbqq
    standardize: true
    train:
      num_jets: null
      path:
        - /home/df630/CMB/data/JetClass/TTBar_000.root
        - /home/df630/CMB/data/JetClass/TTBar_001.root
        - /home/df630/CMB/data/JetClass/TTBar_002.root
    test:
      num_jets: null
      path:
        - /home/df630/CMB/data/JetClass/TTBar_003.root
  source: 
    name: gauss
    standardize: true
    gauss_std: 1.0
    concentration: null  # beta concentration parameter for beta-gauss
    init_state_config: uniform
    train:
      num_jets: null
      path: null
    test:
      num_jets: 2000
      path: null

  min_num_particles: 0
  max_num_particles: 128

  dim:
    features:
      continuous: 3    # pt_rel, eta_rel, phi_phi
      discrete: 1      # flavor/charge
    context:
      continuous: 0
      discrete: 0      
  
  vocab:
    size: 
      features: 8  # mask, gamma, h0, h-, h+, e-, e+, mu-, mu+ 
      context: 0   # t->bqq, t->bql, ...

#...Model parameters

model: 
  name: HybridEPiC
  num_blocks: 10

  dim:
    embed:
      time: 16
      features:
        continuous: 16
        discrete: 16
      context:
        continuous: 0
        discrete: 0
    hidden: 
      local: 128
      glob: 16

  embed_type:
    time: SinusoidalPositionalEncoding
    features: 
      continuous: Linear
      discrete: Linear
    context:
      continuous: null
      discrete: null

  skip_connection: true
  dropout: 0.1
  activation: SELU

#...Dynamics parameters

dynamics: 
  name: ConditionalMarkovBridge
  loss_weight: 0.1
  loss_weight_fn: null

  continuous:
    process: FlowMatching
    sigma: 0.0001

  discrete:
    process: TelegraphProcess
    gamma: 0.125

#...Pipeline generation parameters

pipeline:
  method: EulerLeapingSolver
  num_timesteps: 1000
  time_eps: 0.001

#...Training parameters

train:
  device: cuda:2
  multi_gpu: false
  batch_size: 1024
  data_split_frac: [0.9, 0.1, 0.0]  # train / val / test
  epochs: 500
  early_stopping: null
  min_epochs: null
  print_epochs: 10
  num_workers: 0
  pin_memory: false

  optimizer:
    name: AdamW
    params:
      lr: 0.001
      weight_decay: 5.0e-5
      betas: [0.9, 0.999]
      eps: 1.e-8
      amsgrad: false
    gradient_clip: 1.0

  scheduler: 
    name: CosineAnnealingLR
    params: 
      T_max: 500
      eta_min: 0.00001
      last_epoch: -1


