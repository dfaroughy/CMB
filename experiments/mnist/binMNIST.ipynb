{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple\n",
    "\n",
    "@dataclass\n",
    "class Configs:\n",
    "    #...general params:\n",
    "    WORKDIR : str = './'   \n",
    "    DEVICE : str = 'cuda:0'\n",
    "    MULTI_GPU : bool = False\n",
    "\n",
    "    #...data params:\n",
    "    DATA : str = None\n",
    "    DATA_TARGET : str = 'mnist'\n",
    "    DATA_SOURCE : str = 'noise'\n",
    "    DIM_INPUT : int = None\n",
    "    DIM_CONTEXT : int = 0\n",
    "    VOCAB_SIZE : int = 2\n",
    "    INPUT_SHAPE : Tuple[float] = field(default_factory = lambda : (1, 28, 28))\n",
    "    FLAT_IMAGE : bool = True\n",
    "\n",
    "    # #...model params:\n",
    "    MODEL : str = 'StateClassifier'\n",
    "    DIM_HIDDEN : int = 128\n",
    "    DIM_TIME_EMB : int = 32\n",
    "    DIM_STATE_EMB : int = 8\n",
    "    NUM_LAYERS : int = 3\n",
    "    DROPOUT : float = 0.1\n",
    "    ACTIVATION : str = 'ReLU'\n",
    "    TIME_EMBEDDING_TYPE : str = 'sinusoidal'\n",
    "\n",
    "    #...training params:\n",
    "    BATCH_SIZE : int = 128\n",
    "    DATA_SPLIT_FRACS : List[float] = field(default_factory = lambda : [0.83334, 0.16667, 0.0])  # train / val / test \n",
    "    EPOCHS: int = 5000\n",
    "    EARLY_STOPPING : int = None\n",
    "    MIN_EPOCHS : int = None \n",
    "    PRINT_EPOCHS : int = None   \n",
    "    NUM_WORKERS : int = 0\n",
    "    PIN_MEMORY: bool = False\n",
    "\n",
    "    #...cjb params:\n",
    "    DYNAMICS : str = 'ConditionalJumpBridge'\n",
    "    GAMMA: float = 0.1\n",
    "\n",
    "    #...optimization & scheduler params:\n",
    "    OPTIMIZER: str = 'Adam'\n",
    "    LR : float = 2e-4\n",
    "    WEIGHT_DECAY : float = 0.0\n",
    "    OPTIMIZER_BETAS : List[float] = field(default_factory = lambda : [0.9, 0.999])\n",
    "    OPTIMIZER_EPS : float = 1e-8\n",
    "    OPTIMIZER_AMSGRAD : bool = False\n",
    "    GRADIENT_CLIP : float = None\n",
    "    SCHEDULER: str = None\n",
    "    SCHEDULER_T_MAX: int = None\n",
    "    SCHEDULER_ETA_MIN: float = None\n",
    "    SCHEDULER_GAMMA: float = None\n",
    "    SCHEDULER_STEP_SIZE: int = None\n",
    "\n",
    "    #...generation pipeline params:\n",
    "    SAMPLER : str = 'TauLeaping'\n",
    "    NUM_TIMESTEPS : int = 100\n",
    "    TIME_EPS : float = 1e-3\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.DATA = self.DATA_SOURCE + '_to_' + self.DATA_TARGET\n",
    "        self.DIM_INPUT = np.prod(self.INPUT_SHAPE)\n",
    "        if self.MULTI_GPU: self.DEVICE = 'cuda:0'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: building dataloaders...\n",
      "INFO: train/val/test split ratios: 0.83334/0.16667/0.0\n",
      "INFO: train size: 58333, validation size: 11666, testing sizes: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAA4CAAAAADLW8doAAABG0lEQVR4nMWSSQ7DMAwDh0b//2X2oMVL0u1UI0AUyaQkMmCwAYzp2DPXcXxg+rbtJZXYCuMpTDIBFkZgWWBQpooFF8JzHDB+ALK6ocAKEqtG7Z7V0sZiaWag2mmu2VPX/BnOPeMulcQDjIhN3CIYgWSEmT2jlwAYMbsCljuUyKNTyMGGjGS1Eaw+tSPKWO79OhvTltBK4QowMFZOn1wxcJClS+FAtMipUo5pf0m4vt3ZRcOkzQlTqvw3Wkqva3rDe0pQzrkUbnvLhfj22ISSQn/VTXK5Vr+W5i+n/LydoEQ7LscZX9DS7GviLfIsbkyPnfT1TZ+5vTj/hpfHF/4fqvEa19QMx22NK/J98cTqvqQTeW/2Ffyn3/LjeQLUPRKKcBM/8wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x56>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms import ToPILImage\n",
    "from cmb.data.binary_mnist import MNISTDataClass\n",
    "from cmb.data.utils import DefineDataloader\n",
    "\n",
    "conf = Configs()\n",
    "mnist = MNISTDataClass(conf)\n",
    "dataloader = DefineDataloader(mnist)\n",
    "transform = ToPILImage()\n",
    "\n",
    "for batch in dataloader.train:\n",
    "    pair = torch.cat([batch.source[0].view(1, 28,28), batch.target[0].view( 1, 28,28)], dim=1)\n",
    "    img = transform(pair)\n",
    "    break\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmb.dynamics.cjb import ConditionalJumpBridge\n",
    "from cmb.models.architectures.state_classifier import StateClassifier \n",
    "from cmb.models.trainers import CMBTrainer\n",
    "\n",
    "conf = Configs()\n",
    "mnist = MNISTDataClass(conf)\n",
    "dynamics = ConditionalJumpBridge(conf)\n",
    "classifier = StateClassifier(conf)\n",
    "generative_model = CMBTrainer(dynamics, classifier, mnist)\n",
    "generative_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "class TransitionRateModel(torch.nn.Module):\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__()\n",
    "        self.model = model # model should output logits\n",
    "        self.vocab_size = config.VOCAB_SIZE\n",
    "        self.config = config\n",
    "        self.gamma = config.GAMMA\n",
    "        self.time_epsilon = config.TIME_EPS\n",
    "\n",
    "    def forward(self, t, s, context=None):\n",
    "        t = t.squeeze()\n",
    "        if len(s.shape) != 2:\n",
    "            s = s.reshape(s.size(0),-1)\n",
    "        logits = self.model(t, s, context)\n",
    "        t1 = 1. - self.time_epsilon\n",
    "        beta_integral = (t1 - t) * self.gamma\n",
    "        wt = torch.exp(-self.vocab_size * beta_integral)\n",
    "        A, B, C = 1. , (wt * self.vocab_size)/(1. - wt) , wt\n",
    "        qx = softmax(logits, dim=2)\n",
    "        qy = torch.gather(qx, 2, s.long().unsqueeze(2))\n",
    "        rate = A + B[:, None, None] * qx + C[:, None, None] * qy\n",
    "        return rate\n",
    "\n",
    "class TauLeapingSolver:\n",
    "    def __init__(self, transition_rate, device):\n",
    "        self.transition_rate = transition_rate\n",
    "        self.device = device\n",
    "\n",
    "    def simulate(self, x, t_span):\n",
    "        time_steps = len(t_span)\n",
    "        tau = (t_span[-1] - t_span[0]) / (time_steps - 1)\n",
    "        trajectory = [x]\n",
    "\n",
    "        for i in range(1, time_steps):\n",
    "            t = t_span[i-1]\n",
    "    \n",
    "            current_state = x.clone()\n",
    "            rates = self.transition_rate(t, current_state).to(self.device)\n",
    "            voc_size = rates.size(-1) \n",
    "            \n",
    "            jumps = torch.poisson(rates * tau).to(self.device)  \n",
    "\n",
    "            net_jumps = torch.argmax(jumps, dim=-1).type_as(current_state)\n",
    "\n",
    "            x = torch.clamp(net_jumps, min=0, max=voc_size-1)            \n",
    "\n",
    "            trajectory.append(x.clone())\n",
    "\n",
    "        return torch.stack(trajectory)\n",
    "\n",
    "class ContextWrapper(torch.nn.Module):\n",
    "    \"\"\" Wraps model to torchdyn compatible format.\n",
    "    \"\"\"\n",
    "    def __init__(self, net, context=None):\n",
    "        super().__init__()\n",
    "        self.nn = net\n",
    "        self.context = context\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        t = t.repeat(x.shape[0])\n",
    "        t = self.reshape_time_like(t, x)\n",
    "        return self.nn(t=t, s=x, context=self.context)\n",
    "\n",
    "    def reshape_time_like(self, t, x):\n",
    "        if isinstance(t, (float, int)): return t\n",
    "        else: return t.reshape(-1, *([1] * (x.dim() - 1)))\n",
    "\n",
    "\n",
    "class CJBPipeline:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 trained_model, \n",
    "                 config: dataclass=None,\n",
    "                 best_epoch_model: bool=True,\n",
    "                 ):\n",
    "\n",
    "        self.config = config\n",
    "        self.model = trained_model.best_epoch_model if best_epoch_model else trained_model.last_epoch_model\n",
    "        self.num_sampling_steps = config.NUM_TIMESTEPS\n",
    "        self.sampler = config.SAMPLER\n",
    "        self.device = config.DEVICE\n",
    "        self.vocab_size = config.VOCAB_SIZE\n",
    "        self.has_context = True if config.DIM_CONTEXT > 0 else False\n",
    "        self.time_steps = torch.linspace(0.0, 1.0 - config.TIME_EPS, self.num_sampling_steps, device=self.device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate_samples(self, input_source, context=None):\n",
    "        self.source = input_source.to(self.device) \n",
    "        self.context = context.to(self.device) if self.has_context else None\n",
    "        self.jumps = self.MarkovSolver() \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def MarkovSolver(self):\n",
    "        rate = TransitionRateModel(self.model, self.config)\n",
    "        rate = ContextWrapper(rate, context=self.context if self.context is not None else None)\n",
    "        tauleap = TauLeapingSolver(transition_rate=rate, device=self.device)        \n",
    "        return tauleap.simulate(x=self.source, t_span=self.time_steps).detach().cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 13:23:52.107076: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-08 13:23:53.933651: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-08 13:23:53.942425: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-08 13:23:59.371248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m mnist \u001b[39m=\u001b[39m MNISTDataClass(conf)\n\u001b[1;32m      9\u001b[0m dynamics \u001b[39m=\u001b[39m ConditionalJumpBridge(conf)\n\u001b[0;32m---> 10\u001b[0m classifier \u001b[39m=\u001b[39m StateClassifier(conf)\n\u001b[1;32m     11\u001b[0m generative_model \u001b[39m=\u001b[39m CMBTrainer(dynamics, classifier, mnist)\n\u001b[1;32m     12\u001b[0m generative_model\u001b[39m.\u001b[39mload(model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/CMB/src/cmb/models/architectures/state_classifier.py:16\u001b[0m, in \u001b[0;36mStateClassifier.__init__\u001b[0;34m(self, configs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefine_deep_models(configs)\n\u001b[1;32m     15\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_weights()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/.conda/envs/flow_match_env/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/.conda/envs/flow_match_env/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/flow_match_env/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/flow_match_env/lib/python3.9/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/flow_match_env/lib/python3.9/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from cmb.dynamics.cjb import ConditionalJumpBridge\n",
    "from cmb.models.architectures.state_classifier import StateClassifier \n",
    "from cmb.models.trainers import CMBTrainer\n",
    "from cmb.data.binary_mnist import MNISTDataClass\n",
    "\n",
    "conf = Configs()\n",
    "conf.WORKDIR = 'mnist/mnist_results_500epochs'\n",
    "mnist = MNISTDataClass(conf)\n",
    "dynamics = ConditionalJumpBridge(conf)\n",
    "classifier = StateClassifier(conf)\n",
    "generative_model = CMBTrainer(dynamics, classifier, mnist)\n",
    "generative_model.load(model='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of timesteps: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conf.GAMMA = 0.0001\n",
    "conf.NUM_TIMESTEPS = N = 100 # int(2. / conf.GAMMA)\n",
    "conf.TIME_EPS = 0.0\n",
    "\n",
    "pipeline = CJBPipeline(trained_model=generative_model, config=conf)\n",
    "input_source = torch.randint(0, 2, (128, 784))\n",
    "\n",
    "pipeline.generate_samples(input_source)\n",
    "sample = pipeline.jumps.view(N, 128, 1, 28, 28).float()\n",
    "\n",
    "print('number of timesteps: {}'.format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=308x560>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "transform = ToPILImage()\n",
    "generated_sample = []\n",
    "\n",
    "for idx in random.sample(range(0, 128), 20):\n",
    "    img = []\n",
    "    for time_step in range(0, N, N//10):\n",
    "        img.append(sample[time_step, idx,:,:,:]) \n",
    "    img.append(sample[-1, idx,:,:,:]) \n",
    "    img = torch.cat(img, dim=-1)\n",
    "    generated_sample.append(img)\n",
    "\n",
    "generated_sample = torch.cat(generated_sample, dim=1)\n",
    "transform(generated_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow_match_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
